{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuMB5xs8loWo"
   },
   "source": [
    "## SQL Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WduIsM2MmESY",
    "outputId": "15da31e0-910f-4636-9b55-c58bbfbbd3d1"
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8yn1eXe9mKCW"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "api_key = \"sk--------------------------------------------------rV\"\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For explanations, practices, prompts and examples:**\n",
    "\n",
    "https://platform.openai.com/examples\n",
    "\n",
    "**very detailed official explanation about api reference**\n",
    "\n",
    "https://platform.openai.com/docs/api-reference/introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cXZDa1FwTO2D"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"### Microsoft SQL tables, with their properties:\n",
    "#\n",
    "# Employee(id, name, department_id)\n",
    "# Department(id, name, address)\n",
    "# Sales_amount(id, employee_id, amount, date)\n",
    "#\n",
    "### A query to list the names of employees whose total sales in the last 3 months have been more than 10 thousand EURO\n",
    "SELECT\"\"\"  # select ile basla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "Ewezmz6P00gn",
    "outputId": "e92bb4b5-271f-49a7-94ca-4e6fee5c0ca7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Microsoft SQL tables, with their properties:\\n#\\n# Employee(id, name, department_id)\\n# Department(id, name, address)\\n# Sales_amount(id, employee_id, amount, date)\\n#\\n### A query to list the names of employees whose total sales in the last 3 months have been more than 10 thousand EURO\\nSELECT'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJBduWlkltl7"
   },
   "outputs": [],
   "source": [
    "# propmt yapisni icinde kullanmak uzere bu kodu direkt sitesinden aliyoruz: \n",
    "# https://platform.openai.com/examples/default-sql-translate\n",
    "\n",
    "import openai\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=150,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"#\", \";\"]  # tekrar basa donmemesi icin bunu gordugunde dur. bu ounctuations da kendi open.ai exapmples sitesinde bu kod gibi aynenn mevcut\n",
    ")\n",
    "\n",
    "# GPT modellerinde temperature parametresi, çıktının rastgeleliğini/kalitesini kontrol eder. 0 ile 2 arasında ayarlanır, 0 en tahmin edilebilir/en kaliteli\n",
    "# ve 2 en rastgele/en kalitesiz çıktıyı döndürür. \n",
    "# Temperature 0 olduğunda, GPT her seferinde en yüksek olası yanıtı seçer. Temperature parametresi 2 olarak ayarlandığında, çıktının rastgeleliği artar ve çıktı kalitesi çok düşer.\n",
    "# Ancak temperature değeri MAX 0.8 ve civarı değerler tavsiye edilir.\n",
    "# temperature örnek:\n",
    "# \"\"Kahramanımız elindeki kılıcı ile ejderhayı .....\"\" cümlesinde takip eden kelimelerin/tokenlerin olasılıkları %40 öldürdü, %30 yendi, %20 yaraladı, %7 korkuttu, %3 öptü olsun.\n",
    "# temperature 0, 0.1 gibi çok düşük değerler olarak ayarlanırsa model takip eden kelime olarak en yüksek olasılıklı \"öldürdü\" kelimesini seçer.\n",
    "# temperature 0.2, 0.3 gibi düşük değerler ayarlanırsa model takip eden kelime olarak en yüksek olasılıklı \"öldürdü\", \"yendi\" kelimelerinden birini seçer. \n",
    "# temperature 2 civarı değerler seçilirse model takip eden kelime olarak en düşük olasılıklı kelimeler de dahil olmak üzere olası tüm kelimelerden herhangi birini seçer.\n",
    "\n",
    "\n",
    "# GPT modellerinde top_p parametresi, bir sonraki kelimenin model tarafından ne kadar çeşitli şekillerde tahmin edilebileceğini belirler. top_p=1.0 olduğunda model, \n",
    "# tüm olası kelimeleri seçebilir. top_p=0.5 olduğunda ise model, tüm olası kelimelerin ilk %50'lik kısmındaki kelimeleri seçebilir. \n",
    "# Büyük top_p (0.9 ve üzeri) değeri modelin daha fazla, küçük top_p (0.5 ve altı) değeri ise modelin daha az çeşitlilik göstermesine sağlar.\n",
    "# top_p örnek:\n",
    "# yukardaki örnek cümle için top_p 0.7 olarak ayarlanırsa takip eden kelimeyi, en yüksek olasılıktan başlayacak şekilde kümülatif toplamları 0.7'yi (0.4 öldürdü, 0.3 yendi) \n",
    "# geçmeyen kelimeler arasından seçer.\n",
    "\n",
    "# top_p 0.65 olarak ayarlanırsa takip eden kelimeyi, en yüksek olasılıktan başlayacak şekilde kümülatif toplamları 0.65'i (0.4 öldürdü) geçmeyen kelimeler arasından seçer. Çünkü\n",
    "# 0.4 olasılığa sahip \"öldürdü\" kelimesi ile 0.3 olasılığına sahip \"yendi\" kelimesinin kümülatif olasılık toplamı(0.7) 0.65'den büyük olduğundan sadece en büyük olasılığa sahip\n",
    "# \"öldürdü\" kelimesini seçer \"yendi\" kelimesini ignore eder. \n",
    "\n",
    "# top_p 0.26 olarak ayarlanırsa takip eden kelimeyi, en yüksek olasılıktan başlayacak şekilde kümülatif toplamları 0.26'yı (0.2 yaraladı) geçmeyen kelimeler arasından seçer. Çünkü\n",
    "# 0.2 olasılığa sahip \"yaraladı\" kelimesi ile 0.07 olasılığına sahip \"korkuttu\" kelimesinin kümülatif olasılık toplamı(0.27) 0.26'den büyük olduğundan sadece en büyük olasılığa sahip\n",
    "# \"yaraladı\" kelimesini seçer \"korkuttu\" kelimesini ignore eder.\n",
    "\n",
    "# hem top_p'nin 1 (max) hem de temperature'nin 2 (max) ayarlanması çıktının rassallığını çok fazla artıracağından alınan çıktının kalitesi çok kötü olacaktır. \n",
    "# DİKKAT, ÇOK ÖNEMLİ: 1. En olası çıktıyı elde etmek için top_p'nin her zaman 1, temperaturenin da 0 olarak ayarlanması, \n",
    "#                     2. Çıktının rassalığının artırılması istenirse top_p'nin 1'de sabit bırakılarak sadece temperature hyper_parametresi ile oynanması openai tarafından \n",
    "#                        tavsiye edilmiştir.\n",
    "\n",
    "#  positif değerler : “Frequency penalty”, bir kelimenin kullanım sayısı arttıkça o kelimenin tekrar seçilme olasılığını düşürürken, “presence penalty” bir kelimenin daha \n",
    "# önce kullanılmış olup olmadığına bakarak tekrar seçilme şansını düşürür. Yani “presence penalty”, bir kelimenin ne kadar sıklıkla kullanıldığını dikkate almaz, sadece metinde \n",
    "# var olup olmadığına bakar. Orn surekli ama, ama, ama kullanma onun yrine bazen fakat, lakin vs kullanç\n",
    "\n",
    "# negatif değerler : “Frequency penalty”, bir kelimenin kullanım sayısı arttıkça o kelimenin tekrar seçilme olasılığını artırır, “presence penalty” bir kelimenin daha \n",
    "# önce kullanılmış olup olmadığına bakarak tekrar seçilme şansını artırır.\n",
    "\n",
    "# “Frequency penalty”, “presence penalty” -2 ile +2 arasında değer alsa da 0.1 ile 1 arasında değerlerin kullanılması tavsiye edilmiştir. Ama cezalandirmayi\n",
    "# frequence penalty ile kullanmaliyiz. presence penalty, bir kere gectiyse bir token bir kere daha gecmesini cezalandirir, halbuki efektif olan\n",
    "# cok sayida kullanmasini engellemektir. bu da fre penalty ile mumkun. open.ai yukardaki linkte kullanmamiz gereken default paramtere degerlerini veriyor zaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cx-QhwmmprU",
    "outputId": "44585667-1dbd-4b5f-fc73-2c51ad18fbeb"
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z0gDqpP3mqi0",
    "outputId": "04d6770b-e611-4780-8314-329309c8da25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x7ff6e175b790> JSON: {\n",
       "  \"finish_reason\": \"stop\",\n",
       "  \"index\": 0,\n",
       "  \"logprobs\": null,\n",
       "  \"text\": \" e.name \\nFROM Employee e \\nINNER JOIN Sales_amount sa \\nON e.id = sa.employee_id \\nWHERE sa.date > DATEADD(month, -3, GETDATE()) \\nGROUP BY e.name \\nHAVING SUM(sa.amount) > 10000\"\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"choices\"][0] # choices içerisindeki dictionary'e giriş yapıyoruz ve text key'i ile verdigi sql querysini aliyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JgR3ZneZmzzY",
    "outputId": "3bf0d28d-dfa8-473a-cf0b-299a959b26e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT e.name \n",
      "FROM Employee e \n",
      "INNER JOIN Sales_amount sa \n",
      "ON e.id = sa.employee_id \n",
      "WHERE sa.date > DATEADD(month, -3, GETDATE()) \n",
      "GROUP BY e.name \n",
      "HAVING SUM(sa.amount) > 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"SELECT\"+response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ox8ZjaEktq37"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"### Microsoft SQL tables, with their properties:\n",
    "#\n",
    "# Employee(id, name, department_id)\n",
    "# Department(id, name, address)\n",
    "# Sales_amount(id, employee_id, amount, date)\n",
    "#\n",
    "### A query to list the names of employees whose total sales in the last 3 months have been more than 10 thousand EURO\n",
    "SELECT\"\"\"\n",
    "# bu sekilde tablolarin sadece isimlerini ve featurelarini vermemiz yeterli. query'i asagida getirir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdN3o0SqtrEx",
    "outputId": "712bdbcd-ca9b-44e5-cdb3-f157004dec43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT e.name \n",
      "FROM Employee e \n",
      "INNER JOIN Sales_amount sa \n",
      "ON e.id = sa.employee_id \n",
      "WHERE sa.date > DATEADD(month, -3, GETDATE()) \n",
      "GROUP BY e.name \n",
      "HAVING SUM(sa.amount) > 10000\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=150,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"###\", \";\"]\n",
    ")\n",
    "print(\"SELECT\"+response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAsW9UTas7WT"
   },
   "source": [
    "#### With GPT-3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3TaB2gKl3yM"
   },
   "source": [
    "One-Shot Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YlAxs7T43Zd4"
   },
   "outputs": [],
   "source": [
    "system=\"\"\"You are a Microsoft SQL expert. Answer the questions asked to you in the most accurate way. Return only the query that was asked to you.\n",
    "Microsoft SQL tables, with their properties:\n",
    "Employee(id, name, department_id)\n",
    "Department(id, name, address)\n",
    "Sales_amount(id, employee_id, amount, date)\"\"\"\n",
    "\n",
    "user1 = \"write a query to list the names of the employees who live in Ankara\"\n",
    "\n",
    "# modele bir ornek gostererek cok daha accurate cevap vermesini saglayacagiz\n",
    "assistant = \"\"\"SELECT Employee.name \n",
    "FROM Employee \n",
    "JOIN Department \n",
    "ON Employee.department_id = Department.id \n",
    "WHERE Department.address = 'Ankara';\"\"\"\n",
    "\n",
    "user2 = \"write a query to list the names of employees whose total sales in the last 3 months have been more than 10 thousand EURO. just return query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4-j0WCLu3XIj"
   },
   "outputs": [],
   "source": [
    "# f string ile yukarda olsuturdugumuz system, user1 etc variablelarini verip reposnse isteyelim. Bu sekilde bir ornek yaptiktan yani \n",
    "# sisteme talimat verdikten sonra istedigimiz sorulari sorabiliriz\n",
    "# yani ilk calistirma sisteme talimat ve bir ornekle cok cok daha etkinoluyor\n",
    "import openai\n",
    "\n",
    "res = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages=[\n",
    "          {\"role\": \"system\", \"content\": f\"{system}\"},\n",
    "          {\"role\": \"user\", \"content\": f\"{user1}\"},\n",
    "          {\"role\": \"assistant\", \"content\": f\"{assistant}\"},\n",
    "          {\"role\": \"user\", \"content\": f\"{user2}\"}\n",
    "      ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "epr_b10V1I2E",
    "outputId": "4eb852f8-3078-4cf2-d8bd-a41715c44a4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7N1ciOCAHrjEehoaRtoWEJcv4eT1x at 0x7ff6d152e750> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"SELECT Employee.name \\nFROM Employee \\nJOIN Sales_amount \\nON Employee.id = Sales_amount.employee_id \\nWHERE Sales_amount.date >= DATEADD(month, -3, GETDATE()) \\nGROUP BY Employee.id, Employee.name \\nHAVING SUM(Sales_amount.amount) > 10000;\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1685722140,\n",
       "  \"id\": \"chatcmpl-7N1ciOCAHrjEehoaRtoWEJcv4eT1x\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 57,\n",
       "    \"prompt_tokens\": 157,\n",
       "    \"total_tokens\": 214\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fYLWK8V2GVQ",
    "outputId": "57993f15-5369-4e9a-8821-eff3b7be16a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT Employee.name \n",
      "FROM Employee \n",
      "JOIN Sales_amount \n",
      "ON Employee.id = Sales_amount.employee_id \n",
      "WHERE Sales_amount.date >= DATEADD(month, -3, GETDATE()) \n",
      "GROUP BY Employee.id, Employee.name \n",
      "HAVING SUM(Sales_amount.amount) > 10000;\n"
     ]
    }
   ],
   "source": [
    "# extract the query\n",
    "print(res[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "b9lVn9ops9ZI"
   },
   "outputs": [],
   "source": [
    "# bunu bir user-defined function haline getirelim\n",
    "def chatgpt(system, question):\n",
    "\n",
    "  import openai\n",
    "\n",
    "  res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "          {\"role\": \"system\", \"content\": f\"{system}\"},\n",
    "          {\"role\": \"user\", \"content\": f\"{question}\"}],\n",
    "    temperature=0,\n",
    "    top_p=1,\n",
    "    max_tokens=500,\n",
    "    presence_penalty=0,\n",
    "    frequency_penalty=0,\n",
    "\n",
    "    )\n",
    "\n",
    "  return print(res['choices'][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPW-XM6w8c0W",
    "outputId": "7e06da60-fdfa-476b-95ba-254e42380d19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "SELECT e.name\n",
      "FROM Employee e\n",
      "INNER JOIN Sales_amount sa ON e.id = sa.employee_id\n",
      "WHERE sa.date >= DATEADD(month, -3, GETDATE())\n",
      "GROUP BY e.id, e.name\n",
      "HAVING SUM(sa.amount) > 10000\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# call the function to solve a SQL task\n",
    "\n",
    "system = \"\"\"You are a Microsoft SQL expert. Answer the questions asked to you in the most accurate way. Return only the query that was asked to you.\n",
    "Microsoft SQL tables, with their properties:\n",
    "Employee(id, name, department_id)\n",
    "Department(id, name, address)\n",
    "Sales_amount(id, employee_id, amount, date)\"\"\"\n",
    "\n",
    "question = \"write a query to list the names of employees whose total sales in the last 3 months have been more than 10 thousand EURO. just return query\"\n",
    "\n",
    "chatgpt(system, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iX8HwOmBsbh"
   },
   "source": [
    "## Python to natural language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "XHl8-zG8B3IV"
   },
   "outputs": [],
   "source": [
    "# explain what this code does and mean\n",
    "prompt =\"\"\"# Python 3 \n",
    "def remove_common_prefix(x, prefix, ws_prefix): \n",
    "    x[\"completion\"] = x[\"completion\"].str[len(prefix) :] \n",
    "    if ws_prefix: \n",
    "        # keep the single whitespace as prefix \n",
    "        x[\"completion\"] = \" \" + x[\"completion\"] \n",
    "return x \n",
    "\n",
    "# Explanation of what the code does\n",
    "\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3hm1gobQBumb",
    "outputId": "6e939cae-2c5d-4301-ff9d-d756489f45b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code removes a common prefix from a given string. The parameters x, prefix, and ws_prefix are passed into the function. The x parameter is a dataframe containing a column called \"completion\". The prefix parameter is the string that is to be removed from the \"completion\" column. The ws_prefix parameter is a boolean value that determines whether or not a single whitespace should be kept as a prefix. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=500,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"#\"]\n",
    ")\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ejnjHPuCPaf",
    "outputId": "c7ebd2c4-9439-4c19-bde7-2da49a875e4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code defines a function called `remove_common_prefix` that takes three arguments: `x`, `prefix`, and `ws_prefix`. The function removes the common prefix from the \"completion\" column of the input dataframe `x`. \n",
      "\n",
      "First, the function removes the prefix from the \"completion\" column by using the `str` method of pandas dataframe and slicing the string from the length of the prefix to the end of the string. \n",
      "\n",
      "If `ws_prefix` is True, the function adds a single whitespace as the new prefix to the \"completion\" column. \n",
      "\n",
      "Finally, the function returns the modified dataframe `x`.\n"
     ]
    }
   ],
   "source": [
    "# ayni kodu chatgpt ile deneyelim. daha uzunn cevap verir\n",
    "system = \"You are a python 3 expert. Answer the questions asked to you in the most accurate way.\"\n",
    "\n",
    "question = \"\"\"\n",
    "def remove_common_prefix(x, prefix, ws_prefix): \n",
    "    x[\"completion\"] = x[\"completion\"].str[len(prefix) :] \n",
    "    if ws_prefix: \n",
    "        # keep the single whitespace as prefix \n",
    "        x[\"completion\"] = \" \" + x[\"completion\"] \n",
    "return x\n",
    "Explanation of what the code does\"\"\"\n",
    "\n",
    "chatgpt(system, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbLgd1taENty"
   },
   "source": [
    "## Translate programming languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-xz_XhhFE49J"
   },
   "outputs": [],
   "source": [
    "# cevaplari farkli dillerde goruntuleme: orn R'dan Python'a dondurme\n",
    "prompt = \"\"\"##### Translate this code from R into Python3\n",
    "### R\n",
    "    \n",
    "    set.seed(42)\n",
    "    train_index <- createDataPartition(y, p = 0.9, list = FALSE)\n",
    "    X_train <- X[train_index, ]\n",
    "    X_test <- X[-train_index, ]\n",
    "    y_train <- y[train_index]\n",
    "    y_test <- y[-train_index]\n",
    "    \n",
    "### Python3\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kn4LI64-EPh4",
    "outputId": "147e4b87-fbed-4f99-a665-3ba769ef3de1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    np.random.seed(42)\n",
      "    train_index = np.random.choice(len(y), round(0.9*len(y)), replace=False)\n",
      "    X_train = X[train_index]\n",
      "    X_test = X[~train_index]\n",
      "    y_train = y[train_index]\n",
      "    y_test = y[~train_index]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import openai\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=150,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"###\"]\n",
    ")\n",
    "print(response[\"choices\"][0][\"text\"])\n",
    "\n",
    "# bu eski python librarisde kullanilan bir cevap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBKkT4pBFJft",
    "outputId": "1813a56b-9f1f-447a-d71a-91ad377d2bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "np.random.seed(42)\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# chatgpt daha iyi bir cevap dondurdu\n",
    "system = \"You are a python3 and R expert. Answer the questions asked to you in the most accurate way.\"\n",
    "\n",
    "question = \"\"\"\n",
    "set.seed(42)\n",
    "train_index <- createDataPartition(y, p = 0.9, list = FALSE)\n",
    "X_train <- X[train_index, ]\n",
    "X_test <- X[-train_index, ]\n",
    "y_train <- y[train_index]\n",
    "y_test <- y[-train_index]\n",
    "Translate this code from R into Python3\"\"\"\n",
    "\n",
    "chatgpt(system, question)\n",
    "# ama hem np.random.seed kullanip hem de altta random-state kullanmasi amatorce bir cevap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_f2Su2duJwI4"
   },
   "source": [
    "## Explain Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HdEhvfVEJulg"
   },
   "outputs": [],
   "source": [
    "# explain this code\n",
    "prompt= \"\"\"\n",
    "class Log:\n",
    "    def __init__(self, path):\n",
    "        dirname = os.path.dirname(path)\n",
    "        os.makedirs(dirname, exist_ok=True)\n",
    "        f = open(path, \"a+\")\n",
    "\n",
    "        # Check that the file is newline-terminated\n",
    "        size = os.path.getsize(path)\n",
    "        if size > 0:\n",
    "            f.seek(size - 1)\n",
    "            end = f.read(1)\n",
    "            if end != \"\\n\":\n",
    "                f.write(\"\\n\")\n",
    "        self.f = f\n",
    "        self.path = path\n",
    "\n",
    "    def log(self, event):\n",
    "        event[\"_event_id\"] = str(uuid.uuid4())\n",
    "        json.dump(event, self.f)\n",
    "        self.f.write(\"\\n\")\n",
    "\n",
    "    def state(self):\n",
    "        state = {\"complete\": set(), \"last\": None}\n",
    "        for line in open(self.path):\n",
    "            event = json.loads(line)\n",
    "            if event[\"type\"] == \"submit\" and event[\"success\"]:\n",
    "                state[\"complete\"].add(event[\"id\"])\n",
    "                state[\"last\"] = event\n",
    "        return state\n",
    "\n",
    "\\\"\\\"\\\"\n",
    "Here's what the above class is doing, explained in a concise way:\n",
    "1.\"\"\"\n",
    "# give the answer starting 1 and going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gui9qXQyJus6",
    "outputId": "2f420320-a908-4f2b-f7e4-963cc2699720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The __init__ method creates a new file at the given path, and checks that it is newline-terminated.\n",
      "2. The log method adds a new event to the log file, with a unique ID.\n",
      "3. The state method reads the log file and returns a dictionary containing the set of completed tasks and the last successful event.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=300,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\\"\\\"\\\"\"]\n",
    ")\n",
    "print(\"1.\"+response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CChWc6iEKSgZ",
    "outputId": "84312e94-91c6-4b10-a737-0908d061d0c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The above code defines a class called `Log`. Here is what it does:\n",
      "\n",
      "1. The `__init__` method takes a `path` argument and creates a file object at that path. If the directory of the path does not exist, it creates it. It also checks if the file is newline-terminated and adds a newline character if it is not.\n",
      "\n",
      "2. The `log` method takes an `event` argument, adds a unique `_event_id` key to the event dictionary using the `uuid.uuid4()` method, and writes the event dictionary to the file object in JSON format. It also adds a newline character after writing the event.\n",
      "\n",
      "3. The `state` method reads the file object line by line, loads each line as a JSON object, and checks if the object has a `\"type\"` key with the value `\"submit\"` and a `\"success\"` key with the value `True`. If it does, it adds the `\"id\"` key to a set called `\"complete\"` and sets the `\"last\"` key to the current event. Finally, it returns a dictionary with the `\"complete\"` set and the `\"last\"` event.\n"
     ]
    }
   ],
   "source": [
    "# the same code with chat gpt 3.5\n",
    "system = \"You are a python3 expert. explain the python codes asked to you in the most accurate way.\"\n",
    "\n",
    "question = \"\"\"\n",
    "class Log:\n",
    "    def __init__(self, path):\n",
    "        dirname = os.path.dirname(path)\n",
    "        os.makedirs(dirname, exist_ok=True)\n",
    "        f = open(path, \"a+\")\n",
    "\n",
    "        # Check that the file is newline-terminated\n",
    "        size = os.path.getsize(path)\n",
    "        if size > 0:\n",
    "            f.seek(size - 1)\n",
    "            end = f.read(1)\n",
    "            if end != \"\\n\":\n",
    "                f.write(\"\\n\")\n",
    "        self.f = f\n",
    "        self.path = path\n",
    "\n",
    "    def log(self, event):\n",
    "        event[\"_event_id\"] = str(uuid.uuid4())\n",
    "        json.dump(event, self.f)\n",
    "        self.f.write(\"\\n\")\n",
    "\n",
    "    def state(self):\n",
    "        state = {\"complete\": set(), \"last\": None}\n",
    "        for line in open(self.path):\n",
    "            event = json.loads(line)\n",
    "            if event[\"type\"] == \"submit\" and event[\"success\"]:\n",
    "                state[\"complete\"].add(event[\"id\"])\n",
    "                state[\"last\"] = event\n",
    "        return state\n",
    "explain, point by point, what the above class does\"\"\"\n",
    "\n",
    "chatgpt(system, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwPXWuXdLNWN"
   },
   "source": [
    "## Python bug fixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Qu7Bnm7lLSFp"
   },
   "outputs": [],
   "source": [
    "# if we have a bug on our data that we can't solve, we can get help\n",
    "\n",
    "prompt =\"\"\"\n",
    "##### Fix bugs in the below function\n",
    " \n",
    "### Buggy Python\n",
    "import Random\n",
    "a = random.randint(1,12)\n",
    "b = random.randint(1,12)\n",
    "for i in range(10):\n",
    "    question = \"What is \"+a+\" x \"+b+\"? \"\n",
    "    answer = input(question)\n",
    "    if answer = a*b\n",
    "        print (Well done!)\n",
    "    else:\n",
    "        print(\"No.\")\n",
    "    \n",
    "### Fixed Python\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D-_qgVCgLq90",
    "outputId": "e10b86b7-ebc8-4124-b96c-97356db285b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import random\n",
      "a = random.randint(1,12)\n",
      "b = random.randint(1,12)\n",
      "for i in range(10):\n",
      "    question = \"What is \"+str(a)+\" x \"+str(b)+\"? \"\n",
      "    answer = int(input(question))\n",
      "    if answer == a*b:\n",
      "        print (\"Well done!\")\n",
      "    else:\n",
      "        print(\"No.\")\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=300,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"###\"]\n",
    ")\n",
    "print(response[\"choices\"][0][\"text\"])\n",
    "\n",
    "# the bug is about converting a and b to str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OW2hy_wvL5x-",
    "outputId": "70f0b6a4-02af-49a9-c608-62c17a9eb85f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are several errors in the code. Here's the corrected code:\n",
      "\n",
      "```python\n",
      "import random\n",
      "\n",
      "a = random.randint(1, 12)\n",
      "b = random.randint(1, 12)\n",
      "\n",
      "for i in range(10):\n",
      "    question = \"What is \" + str(a) + \" x \" + str(b) + \"? \"\n",
      "    answer = int(input(question))\n",
      "    if answer == a * b:\n",
      "        print(\"Well done!\")\n",
      "    else:\n",
      "        print(\"No.\")\n",
      "```\n",
      "\n",
      "Changes made:\n",
      "- `random` module was imported with a capital R, which is incorrect. It should be `import random`.\n",
      "- The variables `a` and `b` were not converted to strings before concatenating with other strings. I added `str()` to convert them to strings.\n",
      "- The `input()` function returns a string, so the `answer` variable needs to be converted to an integer using `int()`.\n",
      "- The `if` statement had a syntax error. The comparison operator `==` was used instead of `=`. Also, the string \"Well done!\" was not enclosed in quotes.\n",
      "- The `else` statement was missing quotes around the string \"No.\".\n"
     ]
    }
   ],
   "source": [
    "# the same q with chat gpt 3.5\n",
    "system = \"You are a python3 expert. fix bugs in the python codes asked to you in the most accurate way.\"\n",
    "\n",
    "question = \"\"\"\n",
    "import Random\n",
    "a = random.randint(1,12)\n",
    "b = random.randint(1,12)\n",
    "for i in range(10):\n",
    "    question = \"What is \"+a+\" x \"+b+\"? \"\n",
    "    answer = input(question)\n",
    "    if answer = a*b\n",
    "        print (Well done!)\n",
    "    else:\n",
    "        print(\"No.\")\"\"\"\n",
    "\n",
    "chatgpt(system, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IoW38kA6Mhht",
    "outputId": "8dbfe7a5-1b34-4d1a-f022-ddf2a050288d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import random\n",
      "a = random.randint(1,12)\n",
      "b = random.randint(1,12)\n",
      "for i in range(10):\n",
      "    question = \"What is \"+str(a)+\" x \"+str(b)+\"? \"\n",
      "    answer = int(input(question))\n",
      "    if answer == a*b:\n",
      "        print (\"Well done!\")\n",
      "    else:\n",
      "        print(\"No.\")\n"
     ]
    }
   ],
   "source": [
    "# if we add \"just return fixed python codes\" to the end of the query to the system, than we get a more accurate\n",
    "# answer cleaned from redundant explanation\n",
    "system = \"You are a python3 expert. fix bugs in the python codes asked to you in the most accurate way. just return fixed python codes\"\n",
    "\n",
    "question = \"\"\"\n",
    "import Random\n",
    "a = random.randint(1,12)\n",
    "b = random.randint(1,12)\n",
    "for i in range(10):\n",
    "    question = \"What is \"+a+\" x \"+b+\"? \"\n",
    "    answer = input(question)\n",
    "    if answer = a*b\n",
    "        print (Well done!)\n",
    "    else:\n",
    "        print(\"No.\")\"\"\"\n",
    "\n",
    "chatgpt(system, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMPzq6wUO_yX"
   },
   "source": [
    "## JavaScript to Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "JrZbsNwhPBfc"
   },
   "outputs": [],
   "source": [
    "# how to transform a java code to python code\n",
    "prompt=\"\"\"\n",
    "#JavaScript to Python:\n",
    "JavaScript: \n",
    "dogs = [\"bill\", \"joe\", \"carl\"]\n",
    "car = []\n",
    "dogs.forEach((dog) {\n",
    "    car.push(dog);\n",
    "});\n",
    "\n",
    "Python:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "onYk524ZPLVj",
    "outputId": "67363476-6b41-40c3-c74f-caac12c54785"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dogs = [\"bill\", \"joe\", \"carl\"]\n",
      "car = []\n",
      "for dog in dogs:\n",
      "    car.append(dog)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\", # all the models which start with text (completion models) it's very important to\n",
    "    # comply with the code structure of these prompts. otherwise error\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=300,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "voq7UeqDPTgv",
    "outputId": "869f2834-21a8-4fca-f2de-a205d3d56163"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs = [\"bill\", \"joe\", \"carl\"]\n",
      "car = []\n",
      "for dog in dogs:\n",
      "    car.append(dog)\n"
     ]
    }
   ],
   "source": [
    "# how to perform the same task with chatgpt\n",
    "system = \"You are a python3 and javascript expert. Translate this code from javascript into Python3 in the most accurate way.\"\n",
    "\n",
    "question = \"\"\"\n",
    "dogs = [\"bill\", \"joe\", \"carl\"]\n",
    "car = []\n",
    "dogs.forEach((dog) {\n",
    "    car.push(dog);\n",
    "});\"\"\"\n",
    "\n",
    "chatgpt(system, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9uPvluDQaNp"
   },
   "source": [
    "## Write a Python docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "emIPUzTcQbi7"
   },
   "outputs": [],
   "source": [
    "# how to write a docstring to a user defined function\n",
    "prompt=\"\"\"\n",
    "# Python 3 \n",
    "def remove_common_prefix(x, prefix, ws_prefix): \n",
    "    x[\"completion\"] = x[\"completion\"].str[len(prefix) :] \n",
    "    if ws_prefix: \n",
    "        # keep the single whitespace as prefix \n",
    "        x[\"completion\"] = \" \" + x[\"completion\"] \n",
    "return x \n",
    "\n",
    "# An elaborate, high quality docstring for the above function:\n",
    "\\\"\\\"\\\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "mGDEDNL26uvQ",
    "outputId": "e4f88b41-b900-4efe-e750-371ae2ce3795"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n# Python 3 \\ndef remove_common_prefix(x, prefix, ws_prefix): \\n    x[\"completion\"] = x[\"completion\"].str[len(prefix) :] \\n    if ws_prefix: \\n        # keep the single whitespace as prefix \\n        x[\"completion\"] = \" \" + x[\"completion\"] \\nreturn x \\n\\n# An elaborate, high quality docstring for the above function:\\n\"\"\"\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Yb0MJ7nRSFq",
    "outputId": "15297ef1-aec7-4e56-d166-ec2c0601c1da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_common_prefix(x, prefix, ws_prefix)\n",
      "\n",
      "This function removes a common prefix from a given string.\n",
      "\n",
      "Parameters:\n",
      "    x (str): The string to remove the prefix from.\n",
      "    prefix (str): The prefix to remove from the string.\n",
      "    ws_prefix (bool): Whether to keep a single whitespace as the prefix.\n",
      "\n",
      "Returns:\n",
      "    x (str): The string with the prefix removed.\n",
      "\n",
      "Raises:\n",
      "    ValueError: If the prefix is not found in the string.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=150,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"#\", \"\\\"\\\"\\\"\"]\n",
    ")\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H1ldkHllRfsz",
    "outputId": "62c9f2d1-b5f4-44e9-95b8-3551b9ff3458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "Removes a common prefix from a given string in a pandas DataFrame column.\n",
      "\n",
      "Args:\n",
      "    x (pandas.DataFrame): A pandas DataFrame containing a column named \"completion\" that needs to be modified.\n",
      "    prefix (str): The common prefix to be removed from the \"completion\" column.\n",
      "    ws_prefix (bool): A boolean value indicating whether to keep a single whitespace as prefix after removing the common prefix.\n",
      "\n",
      "Returns:\n",
      "    pandas.DataFrame: The modified pandas DataFrame with the common prefix removed from the \"completion\" column.\n",
      "\n",
      "Example:\n",
      "    >>> df = pd.DataFrame({'completion': ['apple', 'apples', 'apricot']})\n",
      "    >>> df = remove_common_prefix(df, 'ap', True)\n",
      "    >>> print(df)\n",
      "         completion\n",
      "    0       ple\n",
      "    1      ples\n",
      "    2     ricot\n",
      "\"\"\"\n"
     ]
    }
   ],
   "source": [
    "# with chatgpt: we can add to the end not to give examples or explain simply etc..\n",
    "system = \"You are a python3 expert. write high quality docstring for Python3 codes given to you the most accurate way.\"\n",
    "\n",
    "question = \"\"\"\n",
    "def remove_common_prefix(x, prefix, ws_prefix): \n",
    "    x[\"completion\"] = x[\"completion\"].str[len(prefix) :] \n",
    "    if ws_prefix: \n",
    "        # keep the single whitespace as prefix \n",
    "        x[\"completion\"] = \" \" + x[\"completion\"] \n",
    "return x \"\"\"\n",
    "\n",
    "chatgpt(system, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kbk_PD6MTBzP"
   },
   "source": [
    "## Edit Codes\n",
    "\n",
    "https://platform.openai.com/docs/api-reference/edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "lazXgBoUTEd2"
   },
   "outputs": [],
   "source": [
    "# give the code as input and instruction for the editing instructions\n",
    "# Editin code is free.\n",
    "def CodeEdit(input, instruction):\n",
    "\n",
    "  import openai\n",
    "\n",
    "  res = openai.Edit.create(\n",
    "    model= \"code-davinci-edit-001\",\n",
    "    input= f\"{input}\",\n",
    "    instruction= f\"{instruction}\",\n",
    "    temperature=0.0,\n",
    "    top_p=1)\n",
    "  return print(res[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8T7_3Wo9TNvY",
    "outputId": "b8c99db3-db44-478d-8c2e-627d35f5c7cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fibonacci(n):\n",
      "    if n == 0:\n",
      "        return 0\n",
      "    elif n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        return fibonacci(n-1) + fibonacci(n-2)\n",
      "\n",
      "print(fibonacci(9))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CodeEdit(input=\" \", instruction=\"Write a function in python that calculates fibonacci\")\n",
    "# input olarak bir bosluk verirsek bunu duzenlenmesi gereken bir kod gibi algilayip kodu verir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WbsF83t8TQxj",
    "outputId": "88ddf311-248e-40da-eff4-c5bf3e6812cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fibonacci(n):\n",
      "    \"\"\"\n",
      "    Returns the nth number in the fibonacci sequence\n",
      "    \"\"\"\n",
      "    if n == 0:\n",
      "        return 0\n",
      "    elif n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        return fibonacci(n-1) + fibonacci(n-2)\n",
      "\n",
      "print(fibonacci(9))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inputu verip instructionla docstr ekle diyelim\n",
    "input = \"\"\"def fibonacci(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)\n",
    "\n",
    "print(fibonacci(9))\"\"\"\n",
    "CodeEdit(input=input, instruction=\"Add docstring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nqrizhh0Tdt3",
    "outputId": "55b82661-de22-404f-ef78-e385c67b7336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fib(n):\n",
      "    \"\"\"\n",
      "    Returns the nth number in the fibonacci sequence\n",
      "    \"\"\"\n",
      "    if n == 0:\n",
      "        return 0\n",
      "    elif n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        return fib(n-1) + fib(n-2)\n",
      "\n",
      "print(fib(9))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = \"\"\"def fibonacci(n):\n",
    "    \\\"\\\"\\\"\n",
    "    Returns the nth number in the fibonacci sequence\n",
    "    \\\"\\\"\\\"\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)\n",
    "\n",
    "print(fibonacci(9))\"\"\"\n",
    "CodeEdit(input=input, instruction=\"Rename the function to fib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1IF6nE1ToUm",
    "outputId": "0fe492e5-b087-4928-c2d0-d14b14fab468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i in range(1,101):\n",
      "    if i%3==0 and i%5==0:\n",
      "        print(i)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instruction=\"1 ile 100 arasındaki 3 ve 5'e bölünen sayıları bulan python3 kodunu yaz\"\n",
    "CodeEdit(input=\" \", instruction=instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3wbaf_CEUD3L",
    "outputId": "a39dc189-357a-4424-bdc2-4dbf9bb74f82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT e.name\n",
      "FROM Employee e\n",
      "INNER JOIN Sales_amount s ON e.id = s.employee_id\n",
      "WHERE s.date BETWEEN DATEADD(MONTH, -5, GETDATE()) AND GETDATE()\n",
      "GROUP BY e.name\n",
      "HAVING SUM(s.amount) >= 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instruction=\"\"\"Microsoft SQL tabloları:\n",
    "\n",
    "Employee(id, name, department_id)\n",
    "Department(id, name, address)\n",
    "Sales_amount(id, employee_id, amount, date)\n",
    "\n",
    "yukarıdaki tablolara göre son 5 ay içerisinde toplam olarak 10 bin tl satış yapan çalışanların isimlerini listeyen query'i yaz\"\"\"\n",
    "CodeEdit(input=\" \", instruction=instruction)\n",
    "# boslugu duzeltme yapilacak kod gibi algilayip sifirdan verdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QMjE2SBmUzcu",
    "outputId": "e34c6150-8f02-45f5-95fb-17e93d51330c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs = [\"bill\", \"joe\", \"carl\"];\n",
      "car = [];\n",
      "for dog in dogs:\n",
      "    car.append(dog);\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input=\"\"\"dogs = [\"bill\", \"joe\", \"carl\"]\n",
    "car = []\n",
    "dogs.forEach((dog) {\n",
    "    car.push(dog);\n",
    "});\"\"\"\n",
    "\n",
    "instruction= \"python'a dönüştür\"\n",
    "\n",
    "CodeEdit(input=input, instruction=instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7qxhOCNa0Pb",
    "outputId": "629833f2-03bb-45d3-b26f-725a57105fda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "df = pd.read_csv(\"data.csv\")\n",
      "\n",
      "X = df.drop([\"y\"], axis=1)\n",
      "y = df[\"y\"]\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert R code to python\n",
    "input = \"\"\"\n",
    "set.seed(42)\n",
    "train_index <- createDataPartition(y, p = 0.9, list = FALSE)\n",
    "X_train <- X[train_index, ]\n",
    "X_test <- X[-train_index, ]\n",
    "y_train <- y[train_index]\n",
    "y_test <- y[-train_index]\"\"\"\n",
    "\n",
    "instruction= \"R'dan python'a dönüştür.\"\n",
    "\n",
    "CodeEdit(input=input, instruction=instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wcFUc14ex8rL"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOsuQXQLx90U"
   },
   "source": [
    "## Count of tokens for gpt-3.5-turbo-0301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eRr_XkQ9cVPH",
    "outputId": "582cc16c-8f37-4f5d-b266-f0cecef812c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "SUlq_cqRx7MN"
   },
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
    "  \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "  import tiktoken\n",
    "  try:\n",
    "      encoding = tiktoken.encoding_for_model(model)\n",
    "  except KeyError:\n",
    "      encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "  if model == \"gpt-3.5-turbo-0301\":  # note: future models may deviate from this\n",
    "      num_tokens = 0\n",
    "      for message in messages:\n",
    "          num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "          for key, value in message.items():\n",
    "              num_tokens += len(encoding.encode(value))\n",
    "              if key == \"name\":  # if there's a name, the role is omitted\n",
    "                  num_tokens += -1  # role is always required and always 1 token\n",
    "      num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "      return num_tokens\n",
    "  else:\n",
    "      raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\n",
    "  See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDQMWSZ-x7MO",
    "outputId": "d227bf8f-4a96-4d49-cbb9-65738473e9eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 prompt tokens counted.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful, pattern-following assistant that translates corporate jargon into plain English.\"},\n",
    "  {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"New synergies will help drive top-line growth.\"},\n",
    "  {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Things working well together will increase revenue.\"},\n",
    "  {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"Let's circle back when we have more bandwidth to touch base on opportunities for increased leverage.\"},\n",
    "  {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Let's talk later when we're less busy about how to do better.\"},\n",
    "  {\"role\": \"user\", \"content\": \"This late pivot means we don't have time to boil the ocean for the client deliverable.\"},\n",
    "]\n",
    "\n",
    "model = \"gpt-3.5-turbo-0301\"\n",
    "\n",
    "print(f\"{num_tokens_from_messages(messages, model)} prompt tokens counted.\")\n",
    "# Should show ~126 total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SgfDH9FlxxGJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
