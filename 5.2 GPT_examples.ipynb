{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7kfK_wz-KeQ",
    "outputId": "e736acf3-1588-438a-c1a6-de901dc0420d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting openai\n",
      "  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
      "Collecting aiohttp (from openai)\n",
      "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
      "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.7 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dMrqb13F-XlB"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "api_key = \"sk-...............................................NP\"\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "su1iDR8H-gkv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zm32IaxE_B-Q"
   },
   "source": [
    "# Questions & Answers\n",
    "\n",
    "https://platform.openai.com/examples/default-qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mP9fAdn9-gqo"
   },
   "outputs": [],
   "source": [
    "system = \"\"\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, \n",
    "trickery, or has no clear answer, I will respond with 'Unknown'.\"\"\"\n",
    "\n",
    "question=\"How does a telescope work?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LbFPGMY--gwu",
    "outputId": "08c25b77-ae65-4843-febf-d175271dc009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A telescope works by collecting and focusing light from distant objects, allowing the user to observe them in greater detail.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-003\",\n",
    "  prompt=system+\"\\nQ: \"+question+\"\\nA: \",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NLmoEowtCVDQ"
   },
   "outputs": [],
   "source": [
    "def QA_bot(system, question):\n",
    "  import openai\n",
    "\n",
    "  response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=system + \"\\nQ: \"+question+\"\\nA: \",\n",
    "    temperature=0,\n",
    "    max_tokens=100,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "    stop=[\"\\n\"]\n",
    "  )\n",
    "  return print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P3uLxwaJCxjv",
    "outputId": "ecf4f41f-42dc-4d49-f15f-2aa4de6601f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78.7 years.\n"
     ]
    }
   ],
   "source": [
    "system = \"\"\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, \n",
    "trickery, or has no clear answer, I will respond with 'Unknown'.\"\"\"\n",
    "\n",
    "question=\"What is human life expectancy in the United States?\"\n",
    "\n",
    "QA_bot(system, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwcU7TfSDHDf",
    "outputId": "05cf5e34-4696-4dfe-d53c-babcdba0de88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Unknown.\n"
     ]
    }
   ],
   "source": [
    "question=\"What is the square root of banana?\"\n",
    "\n",
    "QA_bot(system, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t7Ym4EG5Emgr",
    "outputId": "f557eb8c-d374-4ffa-9b12-dcb2bcfd7b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Athens, Greece.\n"
     ]
    }
   ],
   "source": [
    "question=\"Where were the 2004 Olympics held?\"\n",
    "\n",
    "QA_bot(system, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUwfSHuuF0Nx"
   },
   "source": [
    "### With GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lzbYKOI9F4bW"
   },
   "outputs": [],
   "source": [
    "def chatgpt(system, question, temperature=0, frequency_penalty=0):\n",
    "\n",
    "  import openai\n",
    "\n",
    "  res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "          {\"role\": \"system\", \"content\": f\"{system}\"},\n",
    "          {\"role\": \"user\", \"content\": f\"{question}\"}],\n",
    "    temperature=temperature,\n",
    "    top_p=1.0,\n",
    "    max_tokens=500,\n",
    "    presence_penalty=0,\n",
    "    frequency_penalty=frequency_penalty)\n",
    "\n",
    "  return print(res['choices'][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hR9BS5K1GHi4",
    "outputId": "5fc5be51-9c3a-4adf-c6aa-3d9c783e51c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2004 Summer Olympics were held in Athens, Greece.\n"
     ]
    }
   ],
   "source": [
    "question=\"Where were the 2004 Olympics held?\"\n",
    "\n",
    "chatgpt(system, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXmbddi5Ga9O"
   },
   "source": [
    "# Grammar Correction\n",
    "\n",
    "https://platform.openai.com/examples/default-grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "neapqtCtPave"
   },
   "outputs": [],
   "source": [
    "def GC(system, text):\n",
    "  import openai\n",
    "\n",
    "  response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=system+\"\\n\\n\"+text,\n",
    "    temperature=0,\n",
    "    max_tokens=100,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0\n",
    "  )\n",
    "  return print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h4NdLt_PP8Su",
    "outputId": "5f56feba-9c20-4ba2-d25e-5362de414d1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "She didn't go to the market.\n"
     ]
    }
   ],
   "source": [
    "system = \"Correct the text to standard English:\" # sitedeki promptun yapisini bozmamaya dikkat. orda da en son :\n",
    "\n",
    "text = \"Sh no went to the mrket\"\n",
    "\n",
    "GC(system, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "430xiFZuIoSv",
    "outputId": "436637bb-2ec0-467d-da76-d74543620bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The teacher conducted an exam yesterday and announced the exam scores today.\n"
     ]
    }
   ],
   "source": [
    "system = \"Correct the text to standard English:\"\n",
    "text = \"Te techer condct an exam yesterday and annunce the exam scos today\"\n",
    "\n",
    "GC(system, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "rC0PwxGYQXGu",
    "outputId": "3ec22816-a8ae-48c7-9f1e-def8dd98ca87"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Correct the text to standard English:\\n\\nTe techer condct an exam yesterday and annunce the exam scos today'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system+\"\\n\\n\"+text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKYDzxZILzBQ"
   },
   "source": [
    "### With GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvUM5lK_Gh_E",
    "outputId": "0736a0a0-3a8b-478e-c308-5e40562794a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The teacher conducted an exam yesterday and announced the exam scores today.\n"
     ]
    }
   ],
   "source": [
    "system = \"Correct the text to standard English.\"  # chatgpt olunca prompttaki yapiyi birebir korumak zo-runda degiliz\n",
    "text = \"Te techer condct an exm yestday and annunce the exam scos today\"\n",
    "\n",
    "chatgpt(system, text)\n",
    "# GPT 4 su an herkese acik degil, bu nedenle 3.5 uzerinden devam ediyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxPw4P_MNS71"
   },
   "source": [
    "### With Edit Text\n",
    "\n",
    "https://platform.openai.com/examples/default-text-to-command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "cr7yxk-HNWx8"
   },
   "outputs": [],
   "source": [
    "def TextEdit(input, instruction):\n",
    "\n",
    "  import openai\n",
    "\n",
    "  res = openai.Edit.create(\n",
    "    model= \"text-davinci-edit-001\",\n",
    "    input= f\"{input}\",\n",
    "    instruction= f\"{instruction}\",\n",
    "    temperature=0.0,\n",
    "    top_p=1.0)\n",
    "  return print(res[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZI3oPugZNmij",
    "outputId": "b38edfed-0df4-404c-b24a-4050418b01ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The teacher conducted an exam yesterday and announced the exam scores today.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input= \"Te techer condct an exm yestday and annunce the exam scos today\"\n",
    "\n",
    "instruction =\"Correct the text to standard English\"\n",
    "\n",
    "TextEdit(input, instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOC13pxyPLIZ"
   },
   "source": [
    "# Summarize for a 2nd grader\n",
    "\n",
    "https://platform.openai.com/examples/default-summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "lgfS2KzNPMOG"
   },
   "outputs": [],
   "source": [
    "def summarize(system, text):\n",
    "  import openai\n",
    "\n",
    "  response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=system+\"\\n\\n\"+text,\n",
    "    temperature=0.7,\n",
    "    max_tokens=100,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0\n",
    "  )\n",
    "  return print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QVqsZm6ERRNC",
    "outputId": "22579a73-af6e-4197-e696-bc5d92e7c2c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Jupiter is the fifth planet from the Sun and the biggest in the Solar System. It is so bright that you can see it in the night sky. It is named after the Roman god Jupiter and is usually the third-brightest thing in the night sky after the Moon and Venus.\n"
     ]
    }
   ],
   "source": [
    "system= \"Summarize this for a second-grade student:\"\n",
    "\n",
    "text= \"\"\"Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times \n",
    "that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient \n",
    "civilizations since before recorded history. It is named after the Roman god Jupiter.[19] When viewed from Earth, Jupiter can be bright enough for its reflected light to cast \n",
    "visible shadows,[20] and is on average the third-brightest natural object in the night sky after the Moon and Venus.\"\"\"\n",
    "\n",
    "summarize(system, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6iUz2Z2R77x"
   },
   "source": [
    "### With GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mX_bbQ31R_nq",
    "outputId": "68930773-d617-46d0-8144-ede33192acd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupiter is a really big planet in our Solar System. It's much bigger than all the other planets combined! People have known about Jupiter for a very long time because it's really bright in the night sky. It's named after a Roman god. When we look at Jupiter from Earth, it's very bright and can even make shadows. It's one of the brightest things we can see in the sky, after the Moon and Venus.\n"
     ]
    }
   ],
   "source": [
    "chatgpt(system, text, temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oS3wjR5kUE-n"
   },
   "source": [
    "# English to other languages\n",
    "\n",
    "https://platform.openai.com/examples/default-translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "NluQwSbUUGX_"
   },
   "outputs": [],
   "source": [
    "def translate(system, text):\n",
    "  import openai\n",
    "\n",
    "  response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=system+\"\\n\\n\"+text+\"\\n\\n1. \",\n",
    "    temperature=0.3,\n",
    "    max_tokens=300,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0\n",
    "  )\n",
    "  return print(\"1.\"+response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k2xvqyrgUnj8",
    "outputId": "3c7088ec-2444-469f-babe-ef7fb7a6a097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Quels sont les chambres que vous avez disponibles ?\n",
      "2. ¿Qué habitaciones tienes disponibles?\n",
      "3. Sizin mevcut olan oda tipleriniz nelerdir?\n",
      "4. どんな部屋がありますか？\n"
     ]
    }
   ],
   "source": [
    "system=\"Translate the text into 1. French, 2. Spanish 3. Turkish and 4. Japanese:\"\n",
    "\n",
    "text=\"What rooms do you have available?\"\n",
    "\n",
    "translate(system, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tbmiz_tsVkp7"
   },
   "source": [
    "### With GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ELuYjqn0Vmhj",
    "outputId": "144286c9-bbe3-498e-da08-845724aede36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. French: Quelles chambres avez-vous de disponibles ?\n",
      "2. Spanish: ¿Qué habitaciones tienen disponibles?\n",
      "3. Turkish: Hangi odalarınız müsait?\n",
      "4. Japanese: どの部屋が利用可能ですか？\n"
     ]
    }
   ],
   "source": [
    "system=\"Translate the text into 1. French, 2. Spanish 3. Turkish and 4. Japanese\"\n",
    "\n",
    "text=\"What rooms do you have available?\"\n",
    "\n",
    "chatgpt(system, text, temperature=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJfLr3FVW1e3"
   },
   "source": [
    "# Sentiment Classifier\n",
    "\n",
    "https://platform.openai.com/examples/default-tweet-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "4_7KzLOuW7Lg"
   },
   "outputs": [],
   "source": [
    "def sentiment(system, text):\n",
    "  import openai\n",
    "\n",
    "  response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=system+\"\\n\\ntext:\"+text+\"\\nsentiment: \",\n",
    "    temperature=0,\n",
    "    max_tokens=60,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0\n",
    "  )\n",
    "  return print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pWj9Xq7fXQHx",
    "outputId": "e8956b8f-d019-4192-dd37-e499cc925a4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Positive\n"
     ]
    }
   ],
   "source": [
    "system=\"Classify the sentiment in the text\"\n",
    "\n",
    "text= \"I loved the new Batman movie!\"\n",
    "\n",
    "sentiment(system, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mW7t6WQpLuIk",
    "outputId": "0a1be20f-9725-4d61-ccf3-41ae390f9757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentiment in the text\n",
      "\n",
      "text:I loved the new Batman movie!\n",
      "sentiment: \n"
     ]
    }
   ],
   "source": [
    "print(system+\"\\n\\ntext:\"+text+\"\\nsentiment: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Btm5CR3ObHdR"
   },
   "source": [
    "### with GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B0z9GP8AN94s",
    "outputId": "ee0b3744-9f87-4ee7-ba72-af4295496e9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "system=\"Classify the sentiment in the text.\"\n",
    "\n",
    "text= \"I loved the new Batman movie!\"\n",
    "\n",
    "chatgpt(system, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nficHtcqbM3o",
    "outputId": "5f28fcdf-42d1-4bff-a6b1-c23cbd181bf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "system=\"Classify the sentiment in the text. just return sentiment\"\n",
    "\n",
    "text= \"I loved the new Batman movie!\"\n",
    "\n",
    "chatgpt(system, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0fWc6Fgciqc"
   },
   "source": [
    "# Extract contact information or customer complaints\n",
    "\n",
    "https://platform.openai.com/examples/default-extract-contact-info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "m0Cscdi0daGh"
   },
   "outputs": [],
   "source": [
    "def contact_info(system, text):\n",
    "  import openai\n",
    "\n",
    "  response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=system+\"\\n\\n\"+text+\"\\nName: \",\n",
    "    temperature=0,\n",
    "    max_tokens=100,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0\n",
    "  )\n",
    "  return print(\"Name:\"+response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXNhfoPIeYK6",
    "outputId": "d02b2f41-9fe8-44ec-c399-0198aa4210fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Kelly \n",
      "Telephone Number: 555 542 2325\n",
      "Mailing Address: 2111 Ash Lane, Crestview CA 92002\n"
     ]
    }
   ],
   "source": [
    "system=\"Extract the name, telephone number and mailing address from this email:\"\n",
    "\n",
    "text= \"\"\"Dear Kelly,\n",
    "\n",
    "It was great to talk to you at the seminar. I thought Jane's talk was quite good.\n",
    "\n",
    "Thank you for the book. Here's my address 2111 Ash Lane, Crestview CA 92002\n",
    "\n",
    "tel.number=555 542 2325\n",
    "\n",
    "Best,\n",
    "\n",
    "Maya\"\"\"\n",
    "\n",
    "contact_info(system, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzmL7LdzfT1B"
   },
   "source": [
    "### with GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ASe6ON3fVpz",
    "outputId": "9fe5b5ce-743d-4154-8071-48a984c18ca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Kelly\n",
      "\n",
      "Telephone number: 555 542 2325\n",
      "\n",
      "Mailing address: 2111 Ash Lane, Crestview CA 92002\n"
     ]
    }
   ],
   "source": [
    "chatgpt(system, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMZUqjnShGTE"
   },
   "source": [
    "### customer complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4g_BRKcfc6I",
    "outputId": "841e1518-6bf6-4fea-ed85-e159c7a53111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical issues: \n",
      "- Freezing and crashing issues with the phone, even when no applications are running\n",
      "- Short battery life and slow charging time\n",
      "\n",
      "Customer service issues:\n",
      "- Long wait times on hold when calling customer service\n",
      "- No solution provided for the technical issues\n",
      "- Representatives were rude and unhelpful.\n"
     ]
    }
   ],
   "source": [
    "system=\"Extract the technical issues and the customer service issues from this complaint\"\n",
    "\n",
    "complaint=\"\"\"I have experienced numerous technical problems and disappointing customer service with a phone I purchased a few weeks ago. First of all, I am constantly experiencing \n",
    "freezing and crashing issues with my phone, even when there are no applications running. This makes using my phone a frustrating and difficult experience. \n",
    "\n",
    "In addition, the battery life of my phone is very short, and it takes a long time to charge. This means that I have to constantly charge my phone, which is very inconvenient. \n",
    "\n",
    "Furthermore, I am very disappointed with the customer service. I have called customer service several times for the issues with my phone, but I have always been put on hold for \n",
    "a long time and no solution was provided. Additionally, I found the representatives to be rude and unhelpful.\n",
    "\n",
    "In conclusion, the technical problems and poor customer service of this phone have left me very disappointed. I am considering contacting the manufacturer or seller to resolve \n",
    "these issues.\"\"\"\n",
    "\n",
    "chatgpt(system, complaint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEndNY5chv6b",
    "outputId": "55cf0a7d-4ca9-4d51-ee94-4bf5f78e09cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative sentiment.\n"
     ]
    }
   ],
   "source": [
    "system = \"Classify the sentiment in the text. just return sentiment\"\n",
    "chatgpt(system, complaint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0Jbr1VJSgCE"
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "cN85GbEcSlBt"
   },
   "outputs": [],
   "source": [
    "def classification(system, text):\n",
    "  import openai\n",
    "\n",
    "  response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=system+\"\\n\\n\"+text+\"\\nApple\\nCategory: \",\n",
    "    temperature=0,\n",
    "    max_tokens=100,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0\n",
    "  )\n",
    "  return print(\"Apple\\nCategory:\"+response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2MKxP5JSwSv",
    "outputId": "8a5941a0-1724-49ac-c959-e78d3401882b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "Category: Technology \n",
      "\n",
      "Facebook\n",
      "Category:  Social Media \n",
      "\n",
      "Fedex\n",
      "Category:  Logistics \n",
      "\n",
      "Samsung\n",
      "Category:  Technology \n",
      "\n",
      "Google\n",
      "Category:  Technology \n",
      "\n",
      "Amazon\n",
      "Category:  Retail\n"
     ]
    }
   ],
   "source": [
    "system = \"The following is a list of companies and the categories they fall into:\"\n",
    "\n",
    "text = \"\"\"Apple, Facebook, Fedex, Samsung, Google, Amazon\"\"\"\n",
    "\n",
    "classification(system, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xG-hjzD-U74Z"
   },
   "source": [
    "### With GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qSiWF_oKU-iI",
    "outputId": "c246bc54-1f11-4d8a-fe0a-2142eeeebc7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple: Technology\n",
      "Facebook: Technology/Social Media\n",
      "Fedex: Logistics/Transportation\n",
      "Samsung: Technology/Electronics\n",
      "Google: Technology/Search Engine\n",
      "Amazon: E-commerce/Retail\n"
     ]
    }
   ],
   "source": [
    "system = \"list companies by category (companies name:category)\"\n",
    "\n",
    "text = \"Apple, Facebook, Fedex, Samsung, Google, Amazon\"\n",
    "\n",
    "chatgpt(system, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdcPHCEbdooQ"
   },
   "source": [
    "# Analogy maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "hH0FUWrvdrz8"
   },
   "outputs": [],
   "source": [
    "def analogy_maker(system, text):\n",
    "  import openai\n",
    "\n",
    "  response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=system+\"\\n\\n\"+text,\n",
    "    temperature=0.5,\n",
    "    max_tokens=100,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0\n",
    "  )\n",
    "  return print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eLxa9_und5Ny",
    "outputId": "3a19184d-50b7-44a9-d5a2-8428674917c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "After hearing the news, he was like a deer in headlights; frozen in shock and unable to speak.\n"
     ]
    }
   ],
   "source": [
    "system = \"Create an analogy for this phrase:\"\n",
    "\n",
    "text =\"After hearing the news, he suddenly became tongue-tied in that:\"\n",
    "\n",
    "analogy_maker(system, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEtoMKnle6E3"
   },
   "source": [
    "### With GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFhAHa7DfJ4S",
    "outputId": "66403694-3a2b-4ff9-eaf5-d2828f5f5b0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was as if a switch had been flipped in his brain, causing his words to become entangled like a ball of yarn. It was like a musician forgetting the notes to a song they had played a thousand times before, or a chef burning their signature dish. His thoughts were like a flock of birds, suddenly scattered and unable to find their way back to their nest.\n"
     ]
    }
   ],
   "source": [
    "system = \"Create an analogy for the text\"\n",
    "\n",
    "text =\"After hearing the news, he suddenly he became tongue-tied\"\n",
    "\n",
    "chatgpt(system, text, temperature=0.5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
